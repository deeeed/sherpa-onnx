<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Sherpa-ONNX Combined Demo</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
      background-color: #f5f5f5;
    }
    h1, h2, h3 {
      color: #333;
    }
    section {
      margin: 20px 0;
      padding: 15px;
      border: 1px solid #ccc;
      border-radius: 8px;
      background-color: #fff;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .controls {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-bottom: 10px;
    }
    .controls input {
      flex-grow: 1;
      padding: 8px;
      border: 1px solid #ccc;
      border-radius: 4px;
    }
    button {
      padding: 8px 16px;
      background-color: #4285f4;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      transition: background-color 0.3s;
    }
    button:hover {
      background-color: #3367d6;
    }
    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    textarea {
      width: 100%;
      height: 100px;
      padding: 8px;
      border: 1px solid #ccc;
      border-radius: 4px;
      resize: vertical;
    }
    .loading {
      display: none;
    }
    #status {
      padding: 10px;
      border-radius: 4px;
      background-color: #e0f7fa;
      margin-bottom: 20px;
    }
    .model-url {
      width: 100%;
      margin-bottom: 5px;
    }
    .module-info {
      margin-top: 20px;
      padding: 15px;
      background-color: #f1f8e9;
      border-radius: 4px;
    }
    /* New styles for form elements */
    .form-group {
      margin-bottom: 12px;
    }
    .form-group label {
      display: block;
      margin-bottom: 5px;
      font-weight: 500;
    }
    .form-group input[type="text"] {
      width: 100%;
      padding: 8px;
      border: 1px solid #ccc;
      border-radius: 4px;
      box-sizing: border-box;
    }
    .form-group small {
      display: block;
      color: #666;
      margin-top: 4px;
      font-size: 0.85em;
    }
    .form-check {
      margin-bottom: 8px;
    }
    .form-check input[type="checkbox"] {
      margin-right: 8px;
    }
    select {
      width: 100%;
      padding: 8px;
      border: 1px solid #ccc;
      border-radius: 4px;
      box-sizing: border-box;
      margin-bottom: 8px;
    }
    .result-box {
      min-height: 100px;
      max-height: 200px;
      overflow-y: auto;
      border: 1px solid #ccc;
      border-radius: 4px;
      padding: 10px;
      margin-top: 10px;
      background-color: #f9f9f9;
    }
    .audio-output {
      margin-top: 15px;
    }
    .audio-item {
      display: flex;
      align-items: center;
      padding: 10px;
      border: 1px solid #ddd;
      border-radius: 4px;
      margin-bottom: 10px;
      background-color: #f9f9f9;
    }
    .audio-item audio {
      margin-right: 10px;
    }
    .audio-item .audio-text {
      flex-grow: 1;
    }
    .audio-item .delete-btn {
      background-color: #f44336;
      color: white;
      border: none;
      border-radius: 4px;
      padding: 5px 10px;
      cursor: pointer;
    }
  </style>
  
  <!-- Load WASM module first -->
  <script src="sherpa-onnx-wasm-combined.js"></script>
  
  <!-- Load the combined module loader script -->
  <script src="sherpa-onnx-combined.js"></script>
  
  <script>
    // Set up initialization callback
    window.onSherpaOnnxReady = function(success, error) {
      if (success) {
        console.log("All SherpaOnnx modules loaded successfully");
        initializeUI();
      } else {
        console.error("Some SherpaOnnx modules failed to load:", error);
        document.getElementById('status').textContent = 
          "Error loading some modules. Some features may not work correctly.";
        document.getElementById('status').style.backgroundColor = "#ffcccc";
        
        // Still try to initialize the UI with available modules
        initializeUI();
      }
    };
    
    // Old-style module initialization for backward compatibility
    window.onModuleReady = function() {
      console.log("WASM module ready - waiting for all JS modules to load");
    };
  </script>
</head>
<body>
  <h1>Sherpa-ONNX Combined Demo</h1>
  <div id="status">Loading WebAssembly module...</div>
  
  <div class="module-info">
    <h3>Modular Design</h3>
    <p>This demo uses a modular architecture. You can load modules individually:</p>
    <pre>
&lt;script src="sherpa-onnx-core.js"&gt;&lt;/script&gt;
&lt;script src="sherpa-onnx-vad.js"&gt;&lt;/script&gt;
    </pre>
    <p>Or load all modules at once:</p>
    <pre>
&lt;script src="sherpa-onnx-combined.js"&gt;&lt;/script&gt;
    </pre>
  </div>

  <section id="vad-section" class="loading">
    <h2>Voice Activity Detection (VAD)</h2>
    
    <div class="model-config">
      <h3>Model Configuration</h3>
      <div class="form-group">
        <label for="vad-model-url">Model URL:</label>
        <input type="text" class="model-url" id="vad-model-url" placeholder="Model URL" value="assets/vad/silero_vad.onnx">
      </div>
      <div class="form-group">
        <label for="vad-model-dir">Model Directory:</label>
        <input type="text" id="vad-model-dir" value="vad-models">
        <small>(The directory where model files will be stored)</small>
      </div>
      <div class="form-check">
        <input type="checkbox" id="vad-debug" checked>
        <label for="vad-debug">Enable debug logging</label>
      </div>
      <div class="form-check">
        <input type="checkbox" id="vad-clean-start">
        <label for="vad-clean-start">Clean start (remove existing files)</label>
      </div>
    </div>
    
    <div class="controls">
      <button id="load-vad-model">Load VAD Model</button>
      <button id="start-vad" disabled>Start</button>
      <button id="stop-vad" disabled>Stop</button>
    </div>
    <div id="vad-status">Status: Not active</div>
  </section>

  <!-- ASR Section -->
  <section id="asr-section" class="loading">
    <h2>Automatic Speech Recognition (ASR)</h2>
    
    <div class="model-config">
      <h3>Model Configuration</h3>
      <div class="form-group">
        <label for="asr-model-type">Model Type:</label>
        <select id="asr-model-type">
          <option value="transducer">Transducer</option>
          <option value="paraformer">Paraformer</option>
          <option value="ctc">CTC</option>
        </select>
      </div>
      <div class="form-group">
        <label for="asr-model-dir">Model Directory:</label>
        <input type="text" id="asr-model-dir" value="asr-models">
        <small>(The directory where model files will be stored)</small>
      </div>
      <div class="form-group transducer-model">
        <label for="asr-encoder-url">Encoder Model URL:</label>
        <input type="text" id="asr-encoder-url" value="assets/asr/encoder.onnx">
      </div>
      <div class="form-group transducer-model">
        <label for="asr-decoder-url">Decoder Model URL:</label>
        <input type="text" id="asr-decoder-url" value="assets/asr/decoder.onnx">
      </div>
      <div class="form-group transducer-model">
        <label for="asr-joiner-url">Joiner Model URL:</label>
        <input type="text" id="asr-joiner-url" value="assets/asr/joiner.onnx">
      </div>
      <div class="form-group">
        <label for="asr-tokens-url">Tokens URL:</label>
        <input type="text" id="asr-tokens-url" value="assets/asr/tokens.txt">
      </div>
      <div class="form-check">
        <input type="checkbox" id="asr-debug" checked>
        <label for="asr-debug">Enable debug logging</label>
      </div>
      <div class="form-check">
        <input type="checkbox" id="asr-clean-start">
        <label for="asr-clean-start">Clean start (remove existing files)</label>
      </div>
    </div>
    
    <div class="controls">
      <button id="load-asr-model">Load ASR Model</button>
      <button id="start-asr" disabled>Start</button>
      <button id="stop-asr" disabled>Stop</button>
    </div>
    <div id="asr-status">Status: Not active</div>
    <div id="asr-result" class="result-box"></div>
  </section>

  <!-- TTS Section -->
  <section id="tts-section" class="loading">
    <h2>Text-to-Speech (TTS)</h2>
    
    <div class="model-config">
      <h3>Model Configuration</h3>
      <div class="form-group">
        <label for="tts-model-type">Model Type:</label>
        <select id="tts-model-type">
          <option value="vits">VITS</option>
          <option value="matcha">Matcha</option>
        </select>
      </div>
      <div class="form-group">
        <label for="tts-model-dir">Model Directory:</label>
        <input type="text" id="tts-model-dir" value="tts-models">
        <small>(The directory where model files will be stored)</small>
      </div>
      <div class="form-group">
        <label for="tts-model-url">Model URL:</label>
        <input type="text" id="tts-model-url" value="assets/tts/model.onnx">
      </div>
      <div class="form-group">
        <label for="tts-tokens-url">Tokens URL:</label>
        <input type="text" id="tts-tokens-url" value="assets/tts/tokens.txt">
      </div>
      <div class="form-group">
        <label for="tts-espeak-url">Espeak-ng-data URL:</label>
        <input type="text" id="tts-espeak-url" value="assets/tts/espeak-ng-data.zip">
        <small>(Required for VITS models)</small>
      </div>
      <div class="form-check">
        <input type="checkbox" id="tts-debug" checked>
        <label for="tts-debug">Enable debug logging</label>
      </div>
      <div class="form-check">
        <input type="checkbox" id="tts-clean-start">
        <label for="tts-clean-start">Clean start (remove existing files)</label>
      </div>
    </div>
    
    <div class="form-group">
      <label for="tts-text">Text to synthesize:</label>
      <textarea id="tts-text" rows="3" placeholder="Enter text to synthesize">Hello, this is a test of the text-to-speech system.</textarea>
    </div>
    
    <div class="controls">
      <button id="load-tts-model">Load TTS Model</button>
      <button id="generate-tts" disabled>Generate Speech</button>
    </div>
    <div id="tts-status">Status: Not active</div>
    <div id="tts-output"></div>
  </section>

  <!-- Keyword Spotting Section -->
  <section id="kws-section" class="loading">
    <h2>Keyword Spotting (KWS)</h2>
    
    <div class="model-config">
      <h3>Model Configuration</h3>
      <div class="form-group">
        <label for="kws-model-dir">Model Directory:</label>
        <input type="text" id="kws-model-dir" value="kws-models">
        <small>(The directory where model files will be stored)</small>
      </div>
      <div class="form-group">
        <label for="kws-encoder-url">Encoder Model URL:</label>
        <input type="text" id="kws-encoder-url" value="assets/kws/encoder.onnx">
      </div>
      <div class="form-group">
        <label for="kws-decoder-url">Decoder Model URL:</label>
        <input type="text" id="kws-decoder-url" value="assets/kws/decoder.onnx">
      </div>
      <div class="form-group">
        <label for="kws-joiner-url">Joiner Model URL:</label>
        <input type="text" id="kws-joiner-url" value="assets/kws/joiner.onnx">
      </div>
      <div class="form-group">
        <label for="kws-tokens-url">Tokens URL:</label>
        <input type="text" id="kws-tokens-url" value="assets/kws/tokens.txt">
      </div>
      <div class="form-group">
        <label for="kws-keywords">Keywords to spot:</label>
        <textarea id="kws-keywords" rows="3" placeholder="Format: h e l l o @Hello">h e l l o @Hello
c o m p u t e r @Computer</textarea>
        <small>Format: Phonetic tokens with spaces between letters, followed by @ and the keyword label</small>
      </div>
      <div class="form-check">
        <input type="checkbox" id="kws-debug" checked>
        <label for="kws-debug">Enable debug logging</label>
      </div>
      <div class="form-check">
        <input type="checkbox" id="kws-clean-start">
        <label for="kws-clean-start">Clean start (remove existing files)</label>
      </div>
    </div>
    
    <div class="controls">
      <button id="load-kws-model">Load KWS Model</button>
      <button id="start-kws" disabled>Start</button>
      <button id="stop-kws" disabled>Stop</button>
    </div>
    <div id="kws-status">Status: Not active</div>
    <div id="kws-result" class="result-box"></div>
  </section>

  <script>
    // Initialize with custom handlers AFTER the WASM module loads
    let audioContext;
    let mediaStream;
    let audioProcessor;
    
    function setupAudioContext() {
      if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({sampleRate: 16000});
      }
      return audioContext;
    }
    
    async function getMicrophoneInput() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({audio: true});
        const context = setupAudioContext();
        mediaStream = context.createMediaStreamSource(stream);
        return stream;
      } catch (error) {
        console.error('Error accessing microphone:', error);
        throw error;
      }
    }
    
    function initializeUI() {
      document.getElementById('status').textContent = 'WebAssembly module loaded. Ready to load models.';
      document.querySelectorAll('section').forEach(section => {
        section.classList.remove('loading');
      });
      
      setupVAD();
      setupASR();
      setupTTS();
      setupKWS();
    }
    
    function setupVAD() {
      const loadBtn = document.getElementById('load-vad-model');
      const startBtn = document.getElementById('start-vad');
      const stopBtn = document.getElementById('stop-vad');
      const statusElem = document.getElementById('vad-status');
      
      let vad = null;
      let vadProcessor = null;
      
      loadBtn.addEventListener('click', async () => {
        loadBtn.disabled = true;
        loadBtn.textContent = 'Loading...';
        statusElem.textContent = 'Status: Loading model...';
        
        try {
          // Get options from UI
          const modelUrl = document.getElementById('vad-model-url').value;
          const modelDir = document.getElementById('vad-model-dir').value || 'vad-models';
          const debug = document.getElementById('vad-debug').checked;
          const cleanStart = document.getElementById('vad-clean-start').checked;
          
          // Build the model config with all options
          const modelConfig = {
            model: modelUrl,
            modelDir: modelDir,
            debug: debug,
            cleanStart: cleanStart
          };
          
          console.log(`VAD setup: Using model configuration:`, modelConfig);
          
          // Load the model
          const loadedModel = await SherpaOnnx.VAD.loadModel(modelConfig);
          
          // Create the VAD detector
          vad = SherpaOnnx.VAD.createVoiceActivityDetector(loadedModel, {
            threshold: 0.5,
            minSilenceDuration: 0.3,
            minSpeechDuration: 0.1,
            windowSize: 512,
            bufferSizeInSeconds: 5.0,
            debug: debug
          });
          
          loadBtn.textContent = 'Model Loaded';
          statusElem.textContent = 'Status: Model loaded successfully';
          startBtn.disabled = false;
        } catch (error) {
          console.error('Failed to load VAD model:', error);
          loadBtn.textContent = 'Load Failed';
          statusElem.textContent = `Status: Error - ${error.message}`;
          loadBtn.disabled = false;
        }
      });
      
      startBtn.addEventListener('click', async () => {
        try {
          await getMicrophoneInput();
          
          const bufferSize = 4096;
          vadProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);
          
          vadProcessor.onaudioprocess = function(e) {
            const samples = new Float32Array(e.inputBuffer.getChannelData(0));
            vad.acceptWaveform(samples);
            
            // Check if speech is detected
            if (vad.detected()) {
              statusElem.textContent = 'Status: Speech detected!';
              statusElem.style.backgroundColor = '#c8e6c9';
            } else {
              statusElem.textContent = 'Status: Silence';
              statusElem.style.backgroundColor = '#ffcdd2';
            }
          };
          
          mediaStream.connect(vadProcessor);
          vadProcessor.connect(audioContext.destination);
          
          startBtn.disabled = true;
          stopBtn.disabled = false;
        } catch (error) {
          console.error('Failed to start VAD:', error);
        }
      });
      
      stopBtn.addEventListener('click', () => {
        if (vadProcessor) {
          vadProcessor.disconnect();
          mediaStream.disconnect();
          vadProcessor = null;
        }
        
        statusElem.textContent = 'Status: Not active';
        statusElem.style.backgroundColor = '';
        
        startBtn.disabled = false;
        stopBtn.disabled = true;
      });
    }
    
    function setupASR() {
      const loadBtn = document.getElementById('load-asr-model');
      const startBtn = document.getElementById('start-asr');
      const stopBtn = document.getElementById('stop-asr');
      const statusElem = document.getElementById('asr-status');
      const resultElem = document.getElementById('asr-result');
      const modelTypeSelect = document.getElementById('asr-model-type');
      
      let asr = null;
      let stream = null;
      let asrProcessor = null;
      let recognizing = false;
      
      // Update UI based on selected model type
      modelTypeSelect.addEventListener('change', () => {
        const modelType = modelTypeSelect.value;
        const transducerElements = document.querySelectorAll('.transducer-model');
        
        transducerElements.forEach(elem => {
          if (modelType === 'transducer') {
            elem.style.display = 'block';
          } else {
            elem.style.display = 'none';
          }
        });
      });
      
      loadBtn.addEventListener('click', async () => {
        loadBtn.disabled = true;
        loadBtn.textContent = 'Loading...';
        statusElem.textContent = 'Status: Loading model...';
        
        try {
          // Get options from UI
          const modelType = modelTypeSelect.value;
          const modelDir = document.getElementById('asr-model-dir').value || 'asr-models';
          const debug = document.getElementById('asr-debug').checked;
          const cleanStart = document.getElementById('asr-clean-start').checked;
          
          // Build the model config with all options
          const modelConfig = {
            modelDir: modelDir,
            type: modelType,
            debug: debug,
            cleanStart: cleanStart
          };
          
          // Add model-specific URLs
          if (modelType === 'transducer') {
            modelConfig.encoder = document.getElementById('asr-encoder-url').value;
            modelConfig.decoder = document.getElementById('asr-decoder-url').value;
            modelConfig.joiner = document.getElementById('asr-joiner-url').value;
            modelConfig.tokens = document.getElementById('asr-tokens-url').value;
          } else if (modelType === 'paraformer') {
            modelConfig.encoder = document.getElementById('asr-encoder-url').value;
            modelConfig.decoder = document.getElementById('asr-decoder-url').value;
            modelConfig.tokens = document.getElementById('asr-tokens-url').value;
          } else if (modelType === 'ctc') {
            modelConfig.model = document.getElementById('asr-encoder-url').value;
            modelConfig.tokens = document.getElementById('asr-tokens-url').value;
          }
          
          console.log(`ASR setup: Using model configuration:`, modelConfig);
          
          // Load the model
          const loadedModel = await SherpaOnnx.ASR.loadModel(modelConfig);
          
          // Create the ASR recognizer
          asr = SherpaOnnx.ASR.createOnlineRecognizer(loadedModel, {
            debug: debug
          });
          
          loadBtn.textContent = 'Model Loaded';
          statusElem.textContent = 'Status: Model loaded successfully';
          startBtn.disabled = false;
        } catch (error) {
          console.error('Failed to load ASR model:', error);
          loadBtn.textContent = 'Load Failed';
          statusElem.textContent = `Status: Error - ${error.message}`;
          loadBtn.disabled = false;
        }
      });
      
      startBtn.addEventListener('click', async () => {
        try {
          await getMicrophoneInput();
          
          // Create an online stream
          stream = asr.createStream();
          
          const bufferSize = 4096;
          asrProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);
          
          asrProcessor.onaudioprocess = function(e) {
            const samples = new Float32Array(e.inputBuffer.getChannelData(0));
            
            // Feed audio to the recognizer
            stream.acceptWaveform(audioContext.sampleRate, samples);
            
            // Check if the stream is ready to be decoded
            if (asr.isReady(stream)) {
              // Decode the audio
              asr.decode(stream);
              
              // Get the result
              const result = asr.getResult(stream);
              
              // Display the result
              if (result && result.text) {
                statusElem.textContent = 'Status: Recognizing...';
                resultElem.textContent = result.text;
              }
            }
          };
          
          mediaStream.connect(asrProcessor);
          asrProcessor.connect(audioContext.destination);
          
          recognizing = true;
          startBtn.disabled = true;
          stopBtn.disabled = false;
          statusElem.textContent = 'Status: Recognizing...';
        } catch (error) {
          console.error('Failed to start ASR:', error);
          statusElem.textContent = `Status: Error - ${error.message}`;
        }
      });
      
      stopBtn.addEventListener('click', () => {
        if (asrProcessor) {
          asrProcessor.disconnect();
          mediaStream.disconnect();
          asrProcessor = null;
        }
        
        if (stream) {
          stream.free();
          stream = null;
        }
        
        recognizing = false;
        statusElem.textContent = 'Status: Not active';
        
        startBtn.disabled = false;
        stopBtn.disabled = true;
      });
    }
    
    function setupTTS() {
      const loadBtn = document.getElementById('load-tts-model');
      const genBtn = document.getElementById('generate-tts');
      const statusElem = document.getElementById('tts-status');
      const textInput = document.getElementById('tts-text');
      const outputContainer = document.getElementById('tts-output');
      
      let tts = null;
      let audioIdx = 0;
      
      loadBtn.addEventListener('click', async () => {
        loadBtn.disabled = true;
        loadBtn.textContent = 'Loading...';
        statusElem.textContent = 'Status: Loading model...';
        
        try {
          // Get options from UI
          const modelType = document.getElementById('tts-model-type').value;
          const modelDir = document.getElementById('tts-model-dir').value || 'tts-models';
          const debug = document.getElementById('tts-debug').checked;
          const cleanStart = document.getElementById('tts-clean-start').checked;
          
          // Build the model config with all options
          const modelConfig = {
            modelDir: modelDir,
            type: modelType,
            debug: debug,
            cleanStart: cleanStart
          };
          
          // Add model-specific URLs
          if (modelType === 'vits') {
            modelConfig.model = document.getElementById('tts-model-url').value;
            modelConfig.tokens = document.getElementById('tts-tokens-url').value;
            modelConfig.espeakDataZip = document.getElementById('tts-espeak-url').value;
          } else if (modelType === 'matcha') {
            modelConfig.acousticModel = document.getElementById('tts-model-url').value;
            modelConfig.vocoder = document.getElementById('tts-model-url').value.replace('model.onnx', 'vocoder.onnx');
            modelConfig.tokens = document.getElementById('tts-tokens-url').value;
          }
          
          console.log(`TTS setup: Using model configuration:`, modelConfig);
          
          // Load the model
          const loadedModel = await SherpaOnnx.TTS.loadModel(modelConfig);
          
          // Create the TTS engine
          tts = SherpaOnnx.TTS.createOfflineTts(loadedModel, {
            debug: debug
          });
          
          loadBtn.textContent = 'Model Loaded';
          statusElem.textContent = 'Status: Model loaded successfully';
          genBtn.disabled = false;
        } catch (error) {
          console.error('Failed to load TTS model:', error);
          loadBtn.textContent = 'Load Failed';
          statusElem.textContent = `Status: Error - ${error.message}`;
          loadBtn.disabled = false;
        }
      });
      
      genBtn.addEventListener('click', async () => {
        try {
          const text = textInput.value.trim();
          
          if (!text) {
            statusElem.textContent = 'Status: No text provided';
            return;
          }
          
          statusElem.textContent = 'Status: Generating speech...';
          genBtn.disabled = true;
          
          // Generate speech
          const result = tts.generate(text, 0, 1.0);
          
          // Convert to WAV
          const blob = tts.saveAsWav(result.samples, result.sampleRate);
          const url = URL.createObjectURL(blob);
          
          // Create audio element
          const audioContainer = document.createElement('div');
          audioContainer.className = 'audio-item';
          
          const audio = document.createElement('audio');
          audio.controls = true;
          audio.src = url;
          
          const textDiv = document.createElement('div');
          textDiv.className = 'audio-text';
          textDiv.textContent = text;
          
          const deleteBtn = document.createElement('button');
          deleteBtn.className = 'delete-btn';
          deleteBtn.textContent = 'Delete';
          deleteBtn.onclick = () => {
            outputContainer.removeChild(audioContainer);
            URL.revokeObjectURL(url);
          };
          
          audioContainer.appendChild(audio);
          audioContainer.appendChild(textDiv);
          audioContainer.appendChild(deleteBtn);
          
          outputContainer.insertBefore(audioContainer, outputContainer.firstChild);
          
          audio.play();
          
          statusElem.textContent = 'Status: Speech generated successfully';
          genBtn.disabled = false;
          
          // Auto-increment audio index
          audioIdx++;
        } catch (error) {
          console.error('Failed to generate speech:', error);
          statusElem.textContent = `Status: Error - ${error.message}`;
          genBtn.disabled = false;
        }
      });
    }
    
    function setupKWS() {
      const loadBtn = document.getElementById('load-kws-model');
      const startBtn = document.getElementById('start-kws');
      const stopBtn = document.getElementById('stop-kws');
      const statusElem = document.getElementById('kws-status');
      const resultElem = document.getElementById('kws-result');
      
      let kws = null;
      let stream = null;
      let kwsProcessor = null;
      
      loadBtn.addEventListener('click', async () => {
        loadBtn.disabled = true;
        loadBtn.textContent = 'Loading...';
        statusElem.textContent = 'Status: Loading model...';
        
        try {
          // Get options from UI
          const modelDir = document.getElementById('kws-model-dir').value || 'kws-models';
          const debug = document.getElementById('kws-debug').checked;
          const cleanStart = document.getElementById('kws-clean-start').checked;
          const keywords = document.getElementById('kws-keywords').value || 'h e l l o @Hello';
          
          // Build the model config with all options
          const modelConfig = {
            modelDir: modelDir,
            encoder: document.getElementById('kws-encoder-url').value,
            decoder: document.getElementById('kws-decoder-url').value,
            joiner: document.getElementById('kws-joiner-url').value,
            tokens: document.getElementById('kws-tokens-url').value,
            debug: debug,
            cleanStart: cleanStart
          };
          
          console.log(`KWS setup: Using model configuration:`, modelConfig);
          
          // Load the model
          const loadedModel = await SherpaOnnx.KWS.loadModel(modelConfig);
          
          // Create the KWS detector with custom keywords
          kws = SherpaOnnx.KWS.createKeywordSpotter(loadedModel, {
            debug: debug,
            keywords: keywords  // Use keywords from the input field
          });
          
          loadBtn.textContent = 'Model Loaded';
          statusElem.textContent = 'Status: Model loaded successfully';
          startBtn.disabled = false;
        } catch (error) {
          console.error('Failed to load KWS model:', error);
          loadBtn.textContent = 'Load Failed';
          statusElem.textContent = `Status: Error - ${error.message}`;
          loadBtn.disabled = false;
        }
      });
      
      startBtn.addEventListener('click', async () => {
        try {
          await getMicrophoneInput();
          
          // Create a stream
          stream = kws.createStream();
          
          const bufferSize = 4096;
          kwsProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);
          
          kwsProcessor.onaudioprocess = function(e) {
            const samples = new Float32Array(e.inputBuffer.getChannelData(0));
            
            // Feed audio to the recognizer
            stream.acceptWaveform(audioContext.sampleRate, samples);
            
            // Check if the stream is ready to be decoded
            if (kws.isReady(stream)) {
              // Decode the audio
              kws.decode(stream);
              
              // Get the result
              const result = kws.getResult(stream);
              
              // Display the result if a keyword is detected
              if (result && result.keyword) {
                statusElem.textContent = `Status: Keyword detected: ${result.keyword}`;
                
                // Add the result to the output
                const item = document.createElement('div');
                item.textContent = `Detected: ${result.keyword} (${new Date().toLocaleTimeString()})`;
                resultElem.insertBefore(item, resultElem.firstChild);
                
                // Reset the stream after detection
                kws.reset(stream);
              }
            }
          };
          
          mediaStream.connect(kwsProcessor);
          kwsProcessor.connect(audioContext.destination);
          
          startBtn.disabled = true;
          stopBtn.disabled = false;
          statusElem.textContent = 'Status: Listening for keywords...';
        } catch (error) {
          console.error('Failed to start KWS:', error);
          statusElem.textContent = `Status: Error - ${error.message}`;
        }
      });
      
      stopBtn.addEventListener('click', () => {
        if (kwsProcessor) {
          kwsProcessor.disconnect();
          mediaStream.disconnect();
          kwsProcessor = null;
        }
        
        if (stream) {
          stream.free();
          stream = null;
        }
        
        statusElem.textContent = 'Status: Not active';
        
        startBtn.disabled = false;
        stopBtn.disabled = true;
      });
    }
  </script>
</body>
</html> 